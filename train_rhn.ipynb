{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sotoxic.data_helper.data_transformer import DataTransformer\n",
    "from sotoxic.data_helper.data_loader import DataLoader\n",
    "from sotoxic.train.trainer import PyTorchModelTrainer\n",
    "from sotoxic.config import dataset_config \n",
    "\n",
    "import sotoxic.models.pytorch.rhn as rhn\n",
    "import sotoxic.train.trainer as trn\n",
    "importlib.reload(rhn)\n",
    "importlib.reload(trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 100000\n",
    "MAX_SEQUENCE_LENGTH = 300\n",
    "EMBEDDING_SIZE = 300\n",
    "\n",
    "EMBEDDING_FILE='features/crawl-300d-2M.vec'\n",
    "#EMBEDDING_FILE='features/glove.840B.300d.txt'\n",
    "#EMBEDDING_FILE='features/glove.twitter.27B.200d.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading the dataset\")\n",
    "data_transformer = DataTransformer(max_num_words=VOCAB_SIZE, max_sequence_length=MAX_SEQUENCE_LENGTH, char_level=False)\n",
    "data_loader = DataLoader()\n",
    "train_sequences, training_labels, test_sequences = data_transformer.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading pre-trained word embedding.\")\n",
    "embeddings_index = data_loader.load_embedding(EMBEDDING_FILE)\n",
    "embedding_matrix = data_transformer.build_embedding_matrix(embeddings_index)\n",
    "print(\"Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recurrent_higway_classifier():\n",
    "    embedding = nn.Embedding(VOCAB_SIZE, EMBEDDING_SIZE)\n",
    "    embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
    "    embedding.weight.requires_grad=False\n",
    "    return rhn.RecurrentHighwayClassifier(\n",
    "        input_size=EMBEDDING_SIZE,\n",
    "        hidden_size=60, \n",
    "        embedding=embedding,\n",
    "        recurrence_length=2,\n",
    "        recurrent_dropout=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = trn.PyTorchModelTrainer(model_stamp=\"FASTTEXT_RHN_64_64\", epoch_num=300, learning_rate=1e-3,\n",
    "                                  verbose_round=80, shuffle_inputs=False, early_stopping_round=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models, best_logloss, best_auc, best_val_pred = trainer.train_folds(X=train_sequences, y=training_labels,\n",
    "                    fold_count=10, batch_size=256, get_model_func=get_recurrent_higway_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_models, best_logloss, best_auc, best_val_pred = trainer.keep_train_folds(X=train_sequences, y=training_labels,\n",
    "                    fold_count=10, batch_size=256, old_models=models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_logloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fold_preditcions = np.concatenate(best_val_pred, axis=0)\n",
    "training_auc = roc_auc_score(training_labels, train_fold_preditcions)\n",
    "print(\"Training AUC\", training_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Dataset/'\n",
    "TRAIN_DATA_FILE=path + 'train.csv'\n",
    "TEST_DATA_FILE=path + 'test.csv'\n",
    "test_df = pd.read_csv(TEST_DATA_FILE)\n",
    "train_df = pd.read_csv(TRAIN_DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data = test_df\n",
    "CLASSES = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "submit_path_prefix = \"results/rhn/Fasttext-tunedRHN-\" + str(MAX_SEQUENCE_LENGTH) \n",
    "\n",
    "print(\"Predicting testing results...\")\n",
    "test_predicts_list = []\n",
    "for fold_id, model in enumerate(new_models):\n",
    "    test_predicts = model.predict(test_sequences, batch_size=256, verbose=1)\n",
    "    test_predicts_list.append(test_predicts)\n",
    "\n",
    "test_predicts = np.zeros(test_predicts_list[0].shape)\n",
    "for fold_predict in test_predicts_list:\n",
    "    test_predicts += fold_predict\n",
    "test_predicts /= len(test_predicts_list)\n",
    "\n",
    "test_ids = test_df[\"id\"].values\n",
    "test_ids = test_ids.reshape((len(test_ids), 1))\n",
    "\n",
    "test_predicts = pd.DataFrame(data=test_predicts, columns=CLASSES)\n",
    "test_predicts[\"id\"] = test_ids\n",
    "test_predicts = test_predicts[[\"id\"] + CLASSES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_path = submit_path_prefix + \"-L{:4f}-A{:4f}.csv\".format(best_logloss, best_auc)\n",
    "test_predicts.to_csv(submit_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = train_df[\"id\"].values\n",
    "train_ids = train_ids.reshape((len(train_ids), 1))\n",
    "\n",
    "train_predicts = pd.DataFrame(data=train_fold_preditcions, columns=CLASSES)\n",
    "train_predicts[\"id\"] = train_ids\n",
    "train_predicts = train_predicts[[\"id\"] + CLASSES]\n",
    "submit_path = submit_path_prefix + \"-Train-L{:4f}-A{:4f}.csv\".format(best_logloss, best_auc)\n",
    "train_predicts.to_csv(submit_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
