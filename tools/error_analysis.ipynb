{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('Dataset/train.csv')[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_rnn_predections = \"results/rnn/ensemble/dropout-glove-bigru-attall-lp-ct-550-Train-L0.038997-A0.988497.csv\"\n",
    "prediction_name = 'glove_avrnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_prediction = pd.read_csv(glove_rnn_predections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>1.653767e-07</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>6.006972e-07</td>\n",
       "      <td>8.850254e-06</td>\n",
       "      <td>3.596437e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>8.066584e-08</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>5.550108e-07</td>\n",
       "      <td>2.606218e-06</td>\n",
       "      <td>1.798546e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>0.026721</td>\n",
       "      <td>1.505168e-06</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>5.198874e-05</td>\n",
       "      <td>2.585440e-04</td>\n",
       "      <td>4.311647e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>2.126189e-08</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.119317e-07</td>\n",
       "      <td>1.846098e-07</td>\n",
       "      <td>5.469327e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>0.010817</td>\n",
       "      <td>1.625897e-05</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>1.347025e-04</td>\n",
       "      <td>5.748330e-04</td>\n",
       "      <td>7.742462e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene        threat  \\\n",
       "0  0000997932d777bf  0.000278  1.653767e-07  0.000065  6.006972e-07   \n",
       "1  000103f0d9cfb60f  0.000158  8.066584e-08  0.000008  5.550108e-07   \n",
       "2  000113f07ec002fd  0.026721  1.505168e-06  0.000786  5.198874e-05   \n",
       "3  0001b41b1c6bb37e  0.000008  2.126189e-08  0.000002  1.119317e-07   \n",
       "4  0001d958c54c6e35  0.010817  1.625897e-05  0.001560  1.347025e-04   \n",
       "\n",
       "         insult  identity_hate  \n",
       "0  8.850254e-06   3.596437e-06  \n",
       "1  2.606218e-06   1.798546e-06  \n",
       "2  2.585440e-04   4.311647e-05  \n",
       "3  1.846098e-07   5.469327e-07  \n",
       "4  5.748330e-04   7.742462e-05  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_term_pos(train, pred, check_column):\n",
    "    sub_train = train[check_column]\n",
    "    sub_pred = pred[check_column]\n",
    "    sub_pred = sub_pred.round()\n",
    "    diff = (sub_pred != sub_train) & (sub_train == 1)\n",
    "    print(\"Wrong predections number:\", diff.sum())\n",
    "    pos = pd.DataFrame()\n",
    "    pos['id'] = train[diff]['id']\n",
    "    pos['text'] = train[diff]['comment_text']\n",
    "    pos['pred_val'] = pred[diff][check_column]\n",
    "    pos['label'] = train[diff][check_column]\n",
    "    return pos\n",
    "\n",
    "def get_error_term_neg(train, pred, check_column):\n",
    "    sub_train = train[check_column]\n",
    "    sub_pred = pred[check_column]\n",
    "    sub_pred = sub_pred.round()\n",
    "    diff = (sub_pred != sub_train) & (sub_train == 0)\n",
    "    print(\"Wrong predections number:\", diff.sum())\n",
    "    neg = pd.DataFrame()\n",
    "    neg['id'] = train[diff]['id']\n",
    "    neg['text'] = train[diff]['comment_text']\n",
    "    neg['pred_val'] = pred[diff][check_column]\n",
    "    neg['label'] = train[diff][check_column]\n",
    "    return neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In term: toxic\n",
      "Wrong predections number: 2845\n",
      "Wrong predections number: 2699\n",
      "In term: severe_toxic\n",
      "Wrong predections number: 561\n",
      "Wrong predections number: 960\n",
      "In term: obscene\n",
      "Wrong predections number: 1584\n",
      "Wrong predections number: 1253\n",
      "In term: threat\n",
      "Wrong predections number: 259\n",
      "Wrong predections number: 232\n",
      "In term: insult\n",
      "Wrong predections number: 2467\n",
      "Wrong predections number: 1605\n",
      "In term: identity_hate\n",
      "Wrong predections number: 478\n",
      "Wrong predections number: 669\n"
     ]
    }
   ],
   "source": [
    "for term in train_df.columns.values[2:]:\n",
    "    print(\"In term:\", term)\n",
    "    err_neg = get_error_term_neg(train_df, check_prediction, term)\n",
    "    err_pos = get_error_term_pos(train_df, check_prediction, term)\n",
    "\n",
    "    err_neg.to_csv(\"analysis/ERR-Neg\"+term+\"-\"+prediction_name+\".csv\", index=False)\n",
    "    err_pos.to_csv(\"analysis/ERR-Pos\"+term+\"-\"+prediction_name+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat',\n",
       "       'insult', 'identity_hate'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns.values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
